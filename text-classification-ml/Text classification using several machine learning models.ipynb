{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read file\n",
    "sampleset = pd.read_csv('fulltrainingset.csv', encoding='ansi')\n",
    "\n",
    "# Divide into 80 training and 20 testing\n",
    "trainingset = sampleset[100:]\n",
    "testingset = sampleset[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "# Set up CountVectorizer with n-grams in range 1-3 to obtain features\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "train_features = vectorizer.fit_transform(trainingset.preprocessed_text)\n",
    "test_features = vectorizer.transform(testingset.preprocessed_text.values.astype('str'))\n",
    "\n",
    "# Fit Multinomial Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "model = nb.fit(train_features, trainingset.sentiment)\n",
    "\n",
    "# Now we can use the model to predict classifications for our test features.\n",
    "predictions = model.predict(test_features)\n",
    "accuracy = accuracy_score(testingset.sentiment, predictions)\n",
    "print('A Multinomial NB with training 80 and test 20 obtains an accuracy of ' + str(accuracy))\n",
    "\n",
    "# Apply 3, 6 and 10-fold cross validation for Multinomial Naive Bayes\n",
    "train_features2 = vectorizer.fit_transform(sampleset.preprocessed_text)\n",
    "NBpredictions3 = cross_val_score(model, train_features2, sampleset.sentiment, cv=3)\n",
    "NBpredictions5 = cross_val_score(model, train_features2, sampleset.sentiment, cv=5)\n",
    "NBpredictions10 = cross_val_score(model, train_features2, sampleset.sentiment, cv=10)\n",
    "print('A Multinomial NB with training 80 and test 20 and 3-fold cross validation obtains an accuracy of ' + str(NBpredictions3.mean()))\n",
    "print('A Multinomial NB with training 80 and test 20 and 5-fold cross validation obtains an accuracy of ' + str(NBpredictions5.mean()))\n",
    "print('A Multinomial NB with training 80 and test 20 and 10-fold cross validation obtains an accuracy of ' + str(NBpredictions10.mean()))\n",
    "\n",
    "# Apply ShuffleSplit to use other cross validation strategies by passing a cross validation iterator instead\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "NBcvscore = cross_val_score(model, train_features2, sampleset.sentiment, cv=cv)\n",
    "NBcvscore = NBcvscore.mean()\n",
    "print('A Multinomial NB with training 70 and test 30 and ShuffleSplit obtains an accuracy of ' + str(NBcvscore))\n",
    "\n",
    "# Print prediction outcomes\n",
    "pos = 0\n",
    "neut = 0\n",
    "neg = 0\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] == 0:\n",
    "        neut += 1\n",
    "    if predictions[i] == 1:\n",
    "        pos += 1\n",
    "    if predictions[i] == -1:\n",
    "        neg += 1\n",
    "        \n",
    "print(\"The number of predictions in the test set: \" + str(len(predictions)))\n",
    "print(\"The number of positive predictions: \" + str(pos))\n",
    "print(\"The number of neutral predictions: \" + str(neut))\n",
    "print(\"The number of negative predictions: \" + str(neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "# Model uses 80 training and 20 testing\n",
    "\n",
    "# Fit Linear SVM\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "clfmodel = clf.fit(train_features, trainingset.sentiment)\n",
    "\n",
    "# Predict test features \n",
    "svmpredictions = clfmodel.predict(test_features)\n",
    "svmaccuracy = accuracy_score(testingset.sentiment, svmpredictions)\n",
    "print('A Linear SVM with training 80 and test 20 obtains an accuracy of ' + str(svmaccuracy))\n",
    "\n",
    "# Apply 3, 5 and 10-fold cross validation for a Linear Support Vector Machine\n",
    "train_features3 = vectorizer.fit_transform(sampleset.preprocessed_text)\n",
    "SVMpredictions3 = cross_val_score(clf, train_features3, sampleset.sentiment, cv=3)\n",
    "SVMpredictions5 = cross_val_score(clf, train_features3, sampleset.sentiment, cv=5)\n",
    "SVMpredictions10 = cross_val_score(clf, train_features3, sampleset.sentiment, cv=10)\n",
    "print('A Linear SVM with training 80 and test 20 and 3-fold cross validation obtains an accuracy of ' + str(SVMpredictions3.mean()))\n",
    "print('A Linear SVM with training 80 and test 20 and 5-fold cross validation obtains an accuracy of ' + str(SVMpredictions5.mean()))\n",
    "print('A Linear SVM with training 80 and test 20 and 10-fold cross validation obtains an accuracy of ' + str(SVMpredictions10.mean()))\n",
    "\n",
    "# Apply ShuffleSplit to use other cross validation strategies by passing a cross validation iterator instead\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "svmcvscore = cross_val_score(clf, train_features3, sampleset.sentiment, cv=cv)\n",
    "svmcvscore = svmcvscore.mean()\n",
    "print('A SVM with training 70 and test 30 and ShuffleSplit obtains an accuracy of ' + str(svmcvscore))\n",
    "\n",
    "# Print prediction outcomes\n",
    "pos = 0\n",
    "neut = 0\n",
    "neg = 0\n",
    "for i in range(len(svmpredictions)):\n",
    "    if svmpredictions[i] == 0:\n",
    "        neut += 1\n",
    "    if svmpredictions[i] == 1:\n",
    "        pos += 1\n",
    "    if svmpredictions[i] == -1:\n",
    "        neg += 1\n",
    "        \n",
    "print(\"The number of predictions in the test set: \" + str(len(svmpredictions)))\n",
    "print(\"The number of positive predictions: \" + str(pos))\n",
    "print(\"The number of neutral predictions: \" + str(neut))\n",
    "print(\"The number of negative predictions: \" + str(neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "# Model uses 80 training and 20 testing\n",
    "\n",
    "# Fit Random Forest \n",
    "rf = RandomForestClassifier()\n",
    "rfmodel = rf.fit(train_features, trainingset.sentiment)\n",
    "\n",
    "# Predict test features \n",
    "rfpredictions = rfmodel.predict(test_features)\n",
    "rfaccuracy = accuracy_score(testingset.sentiment, rfpredictions)\n",
    "print('A Random Forest with training 80 and test 20 obtains an accuracy of ' + str(rfaccuracy))\n",
    "\n",
    "# Apply 3, 5 and 10-fold cross validation for a Random Forest\n",
    "train_features4 = vectorizer.fit_transform(sampleset.preprocessed_text)\n",
    "rfpredictions3 = cross_val_score(rf, train_features4, sampleset.sentiment, cv=3)\n",
    "rfpredictions5 = cross_val_score(rf, train_features4, sampleset.sentiment, cv=5)\n",
    "rfpredictions10 = cross_val_score(rf, train_features4, sampleset.sentiment, cv=10)\n",
    "print('A Random Forest with training 80 and test 20 and 3-fold cross validation obtains an accuracy of ' + str(rfpredictions3.mean()))\n",
    "print('A Random Forest with training 80 and test 20 and 5-fold cross validation obtains an accuracy of ' + str(rfpredictions5.mean()))\n",
    "print('A Random Forest with training 80 and test 20 and 10-fold cross validation obtains an accuracy of ' + str(rfpredictions10.mean()))\n",
    "\n",
    "# Apply ShuffleSplit to use other cross validation strategies by passing a cross validation iterator instead\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "rfcvscore = cross_val_score(rf, train_features4, sampleset.sentiment, cv=cv)\n",
    "rfcvscore = rfcvscore.mean()\n",
    "print('A Random Forest with training 70 and test 30 and ShuffleSplit obtains an accuracy of ' + str(rfcvscore))\n",
    "\n",
    "# Print prediction outcomes\n",
    "pos = 0\n",
    "neut = 0\n",
    "neg = 0\n",
    "for i in range(len(rfpredictions)):\n",
    "    if rfpredictions[i] == 0:\n",
    "        neut += 1\n",
    "    if rfpredictions[i] == 1:\n",
    "        pos += 1\n",
    "    if rfpredictions[i] == -1:\n",
    "        neg += 1\n",
    "        \n",
    "print(\"The number of predictions in the test set: \" + str(len(rfpredictions)))\n",
    "print(\"The number of positive predictions: \" + str(pos))\n",
    "print(\"The number of neutral predictions: \" + str(neut))\n",
    "print(\"The number of negative predictions: \" + str(neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Fit Logistic Regression and TF-IDF vectorizer\n",
    "lr = LogisticRegression()\n",
    "tvec = TfidfVectorizer(ngram_range=(1, 3))\n",
    "train_features = tvec.fit_transform(trainingset.preprocessed_text)\n",
    "test_features = tvec.transform(testingset.preprocessed_text.values.astype('str'))\n",
    "model = lr.fit(train_features, trainingset.sentiment)\n",
    "\n",
    "# Now we can use the model to predict classifications for our test features.\n",
    "lrpredictions = model.predict(test_features)\n",
    "lraccuracy = accuracy_score(testingset.sentiment, lrpredictions)\n",
    "print('A Logistic Regression with TFIDF and a training 80 and test 20 obtains an accuracy of ' + str(lraccuracy))\n",
    "\n",
    "# Apply 3, 5 and 10-fold cross validation for a Random Forest\n",
    "train_features5 = vectorizer.fit_transform(sampleset.preprocessed_text)\n",
    "lrpredictions3 = cross_val_score(lr, train_features5, sampleset.sentiment, cv=3)\n",
    "lrpredictions5 = cross_val_score(lr, train_features5, sampleset.sentiment, cv=5)\n",
    "lrpredictions10 = cross_val_score(lr, train_features5, sampleset.sentiment, cv=10)\n",
    "print('A Logistic Regression with training 80 and test 20 and 3-fold cross validation obtains an accuracy of ' + str(lrpredictions3.mean()))\n",
    "print('A Logistic Regression with training 80 and test 20 and 5-fold cross validation obtains an accuracy of ' + str(lrpredictions5.mean()))\n",
    "print('A Logistic Regression with training 80 and test 20 and 10-fold cross validation obtains an accuracy of ' + str(lrpredictions10.mean()))\n",
    "\n",
    "# Apply ShuffleSplit to use other cross validation strategies by passing a cross validation iterator instead\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "lrcvscore = cross_val_score(lr, train_features5, sampleset.sentiment, cv=cv)\n",
    "lrcvscore = lrcvscore.mean()\n",
    "print('A Logistic Regression with training 70 and test 30 and ShuffleSplit obtains an accuracy of ' + str(lrcvscore))\n",
    "\n",
    "# Print prediction outcomes\n",
    "pos = 0\n",
    "neut = 0\n",
    "neg = 0\n",
    "for i in range(len(lrpredictions)):\n",
    "    if lrpredictions[i] == 0:\n",
    "        neut += 1\n",
    "    if lrpredictions[i] == 1:\n",
    "        pos += 1\n",
    "    if lrpredictions[i] == -1:\n",
    "        neg += 1\n",
    "        \n",
    "print(\"The number of predictions in the test set: \" + str(len(predictions)))\n",
    "print(\"The number of positive predictions: \" + str(pos))\n",
    "print(\"The number of neutral predictions: \" + str(neut))\n",
    "print(\"The number of negative predictions: \" + str(neg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
